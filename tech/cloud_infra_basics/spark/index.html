<!DOCTYPE html>
<html><head>
<title>Spark</title>




<meta charset="utf-8">
<meta name="X-UA-Compatible" content="IE=edge">
<meta name="google-site-verification" content="">
<meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport">
<meta content="telephone=no" name="format-detection">
<meta name="description" content="">
<meta name="renderer" content="webkit">
<meta name="theme-color" content="#ffffff">



<meta property="og:title" content="Spark" />
<meta property="og:description" content="Why Spark Hadoop is not that efficient as it is designed for Commodity Hardware while apache spark is designed for more expensive infra with better performance. Performance: MapReduce only supports Full dump of intermediate data to disk between jobs No data sharing between jobs While Spark supports In-memory processing, benefits: MpReduce only supports batch mode Spark Basics Apache Spark is a fast and general-purpose cluster computing system for large scale data processing." />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://allenhsm.github.io/tech/cloud_infra_basics/spark/" /><meta property="article:section" content="tech" />
<meta property="article:published_time" content="2025-12-01T01:42:36-05:00" />
<meta property="article:modified_time" content="2025-12-01T01:42:36-05:00" /><meta property="og:site_name" content="My Blog" />





<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Spark"/>
<meta name="twitter:description" content="Why Spark Hadoop is not that efficient as it is designed for Commodity Hardware while apache spark is designed for more expensive infra with better performance. Performance: MapReduce only supports Full dump of intermediate data to disk between jobs No data sharing between jobs While Spark supports In-memory processing, benefits: MpReduce only supports batch mode Spark Basics Apache Spark is a fast and general-purpose cluster computing system for large scale data processing."/>









<script type="text/javascript">
  (function(c,l,a,r,i,t,y){
      c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
      t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
      y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
  })(window, document, "clarity", "script", "imlbq734pa");
</script>



  



<link rel="icon" type="image/png" href="/favicon/favicon-96x96.png" sizes="96x96" />
<link rel="icon" type="image/svg+xml" href="/favicon/favicon.svg" />
<link rel="shortcut icon" href="/favicon/favicon.ico" />
<link rel="apple-touch-icon" sizes="180x180" href="/favicon/apple-touch-icon.png" />
<link rel="manifest" href="/favicon/site.webmanifest" />



      <script src="/js/toc.js"></script>
    
    <link type="text/css" rel="stylesheet" href="/vendor/css/bootstrap.min.css">

<link rel="stylesheet" href="/scss/dark-mode.min.7b0f5194901cbbe764b7f98b9e95f3168d721166a30785920f943aa8dbb28473.css" integrity="sha256-ew9RlJAcu&#43;dkt/mLnpXzFo1yEWajB4WSD5Q6qNuyhHM=" media="screen">


<link rel="stylesheet"
          href="https://fonts.googleapis.com/css?family=Material+Icons">



















</head>

    <link rel="stylesheet" href="/css/custom.css">
    
    <body>
    	<div id="app"><div class="single-column-drawer-container" id="drawer"
     v-bind:class="{ 'single-column-drawer-container-active': isDrawerOpen }">
    <div class="drawer-content">
        <div class="drawer-menu">
            
            
            
                
                
                
                
                
                <a class="a-block drawer-menu-item false" href="/posts">
                    Archive
                </a>
                
            
                
                
                
                
                
                <a class="a-block drawer-menu-item false" href="/tags/reading">
                    Reading
                </a>
                
            
                
                
                
                
                
                <a class="a-block drawer-menu-item false" href="/tags/travelogue">
                    Travelogue
                </a>
                
            
                
                
                
                
                
                <a class="a-block drawer-menu-item false" href="/categories">
                    Categories
                </a>
                
            
                
                
                
                
                
                <a class="a-block drawer-menu-item false" href="/about/about_me">
                    About Me
                </a>
                
            
                
                
                
                
                
                <a class="a-block drawer-menu-item false" href="/tags">
                    Tags
                </a>
                
            
            
            <div class="toc">


	<div class="toc-content">
	
		
		
		
		<center>- CATALOG -</center>
		
		
		<ul>
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#why-spark" class="nav-why-spark">
									Why Spark
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#spark" class="nav-spark">
									Spark
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
							
								
									<ul>
								
							
						
						
							<li>
								<a href="#basics" class="nav-basics">
									Basics
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#ecosystem" class="nav-ecosystem">
									Ecosystem
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#engine" class="nav-engine">
									Engine
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
							
								
									<ul>
								
							
						
						
							<li>
								<a href="#why-fast" class="nav-why-fast">
									Why Fast?
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
							
								</ul>
							
						
						
						
							<li>
								<a href="#components" class="nav-components">
									Components
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#resilient-distributed-datasets-rdds" class="nav-resilient-distributed-datasets-rdds">
									Resilient Distributed Datasets (RDDs)
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
							
								
									<ul>
								
							
						
						
							<li>
								<a href="#definition" class="nav-definition">
									Definition
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#properties" class="nav-properties">
									Properties
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
							
								</ul>
							
						
						
						
							<li>
								<a href="#programming" class="nav-programming">
									Programming
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#flexible-deployment" class="nav-flexible-deployment">
									Flexible Deployment
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#spark-context" class="nav-spark-context">
									Spark Context
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#spark-dataframes" class="nav-spark-dataframes">
									Spark Dataframes
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
							
								
									<ul>
								
							
						
						
							<li>
								<a href="#spark-2x-entry-point" class="nav-spark-2x-entry-point">
									Spark 2.x Entry Point
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
							
								</ul>
							
						
						
						
							<li>
								<a href="#architecture" class="nav-architecture">
									Architecture
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#run-a-job" class="nav-run-a-job">
									Run a Job
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
							
								</ul>
							
						
						
						
							<li>
								<a href="#dataframe-operations" class="nav-dataframe-operations">
									DataFrame Operations
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
							
								
									<ul>
								
							
						
						
							<li>
								<a href="#readwrite" class="nav-readwrite">
									Read/Write
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#dataframe-schema" class="nav-dataframe-schema">
									DataFrame Schema
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#data-types" class="nav-data-types">
									Data Types
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
							
								
									<ul>
								
							
						
						
							<li>
								<a href="#more-operations" class="nav-more-operations">
									More Operations
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
							
								</ul>
							
								</ul>
							
						
						
						
							<li>
								<a href="#spark-sql" class="nav-spark-sql">
									Spark SQL
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
							
								
									<ul>
								
							
						
						
							<li>
								<a href="#sql-dataframe-operations" class="nav-sql-dataframe-operations">
									SQL DataFrame Operations
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#advantages-over-relational-query-languages" class="nav-advantages-over-relational-query-languages">
									Advantages over Relational Query Languages
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
							
								</ul>
							
						
						
						
							<li>
								<a href="#rdd-operations" class="nav-rdd-operations">
									RDD Operations
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
							
								
									<ul>
								
							
						
						
							<li>
								<a href="#transformations-vs-actions" class="nav-transformations-vs-actions">
									Transformations vs Actions
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
							
								
									<ul>
								
							
						
						
							<li>
								<a href="#transformations" class="nav-transformations">
									Transformations
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#actions" class="nav-actions">
									Actions
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
							
								</ul>
							
						
						
						
							<li>
								<a href="#programming-1" class="nav-programming-1">
									Programming
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
							
								
									<ul>
								
							
						
						
							<li>
								<a href="#single-rdd" class="nav-single-rdd">
									Single RDD
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#pair-rdd" class="nav-pair-rdd">
									Pair RDD
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#two-pair" class="nav-two-pair">
									Two Pair
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
							
								</ul>
							
								</ul>
							
						
						
						
							<li>
								<a href="#top-n-example" class="nav-top-n-example">
									Top-N Example
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#extra-reading" class="nav-extra-reading">
									Extra Reading
								</a>
							</li>
						
						
					
				
			
		</ul>
	</div>

</div>
            
        </div>
    </div>
</div>
<transition name="fade">
    <div id="drawer-mask" v-bind:class="{ 'single-column-drawer-mask': mounted }" v-if="isDrawerOpen" v-on:click="toggleDrawer"></div>
</transition>
<nav id="navBar" class="navbar sticky-top navbar-light single-column-nav-container">
    <div id="navBackground" class="nav-background"></div>
    <div class="container container-narrow nav-content">
        <button id="nav_dropdown_btn" class="nav-dropdown-toggle" type="button" v-on:click="toggleDrawer">
            <i class="material-icons">
                menu
            </i>
        </button>
        <a id="navTitle" class="navbar-brand" href="http://allenhsm.github.io/">
            Allen&#39;s Blog
        </a>
        
        <button type="button" class="nav-darkmode-toggle" id="darkModeToggleButton2">
            <i class="material-icons" id="darkModeToggleIcon2">
                dark_mode
            </i>
        </button>
        
    </div>
</nav>
<div class="single-column-header-container" id="pageHead"
     v-bind:style="{ transform: 'translateZ(0px) translateY('+.3*scrollY+'px)', opacity: 1-navOpacity }">
    <a href="http://allenhsm.github.io/">
        <div class="single-column-header-title">Allen&#39;s Blog</div>
        

    </a>
</div>

            <div id="content">
                <div id="streamContainer" class="stream-container">

    <div class="post-list-container post-list-container-shadow">
        <div class="post">
            
            
            
                
            

            <div class="post-head-wrapper"
                
                    
                    
                    style="background-image: url('http://allenhsm.github.io/images/cloudInfraBasics/spark_logo.png')"
                    
                
            >
                <div class="post-title">
                    Spark
                    
                    <div class="post-meta">
                        
                        <time itemprop="datePublished">
                            2025-12-01 01:42
                        </time>
                        

                        

                        
                            <i class="material-icons" style="">label</i>
                            
                                <a href="/tags/tech">tech</a>
                                &nbsp;
                            
                                <a href="/tags/cloud">cloud</a>
                                &nbsp;
                            
                        
                        
                    </div>
                </div>
            </div>
            
            <div class="post-body-wrapper">
                
                <div class="post-body" v-pre>
                
                    <h1 id="why-spark"><strong>Why Spark</strong></h1>
<ul>
<li>Hadoop is not that efficient as it is designed for <strong>Commodity Hardware</strong> while apache spark is designed for more expensive infra with better performance.</li>
<li>Performance: MapReduce only supports
<ul>
<li>Full <strong>dump of intermediate data to disk</strong> between jobs</li>
<li><strong>No data sharing</strong> between jobs
While Spark supports <strong>In-memory processing</strong>,
benefits: <figure><img src="/images/cloudInfraBasics/spark_inmemory.png"
         alt="mapreduce vs spark" width="65%"/>
</figure>
</li>
</ul>
</li>
<li>MpReduce only supports <strong>batch</strong> mode <figure class="img-center"><img src="/images/cloudInfraBasics/batch_vs_realtime.png"
         alt="mapreduce vs spark" width="65%"/>
</figure>
</li>
</ul>
<h1 id="spark"><strong>Spark</strong></h1>
<h2 id="basics"><strong>Basics</strong></h2>
<ul>
<li>Apache Spark is a <strong>fast</strong> and <strong>general-purpose cluster computing system</strong> for <strong>large scale data processing</strong>.</li>
<li>Spark was originally written in Scala, which allows <strong>concise function syntax</strong> and interactive use.</li>
<li>Scala is a <strong>type-safe Java Virtual Machine</strong> language that incorporates both object oriented and functional programming into an extremely concise, logical, and extraordinarily powerful language.</li>
<li>Apache Spark provides High-level APIs in Java, Scala, Python (PySpark) and R.</li>
<li>Apache Spark combines two different modes of processing:
<ul>
<li>Batch-based Processing which could be provided via Apache Hadoop MapReduce</li>
<li>Real-time Processing which could be provided via <em><strong>Apache Storm</strong></em>.</li>
</ul>
</li>
<li>Spark is run on CPU, and it <strong>can be used on GPU</strong> using <code>Nvidia dgx spark</code> with <code>RAPIDS</code> accelerator.</li>
</ul>
<h2 id="ecosystem"><strong>Ecosystem</strong></h2>
<figure class="img-center"><img src="/images/cloudInfraBasics/spark_ecosystem.png"
         alt="spark ecosystem" width="50%"/>
</figure>

<h2 id="engine"><strong>Engine</strong></h2>
<p><em><strong>Lightning fast cluster computing</strong></em></p>
<p><em><strong>Spark Core</strong></em> is the general execution engine for the Spark platform that other functionalities are built on top of it. Spark has several advantages:</p>
<ul>
<li><strong>Speed</strong>: Run programs up to <strong>100x faster than Hadoop</strong> MapReduce in memory, or 10x faster on disk</li>
<li><strong>Ease of Use</strong>: Write applications quickly in Java, Scala, Python, R</li>
<li><strong>Generality</strong>: Combine SQL, streaming, and complex analytics</li>
<li><strong>Runs Everywhere</strong>:
<ul>
<li>Spark runs on Hadoop, Mesos, standalone, or in the cloud</li>
<li>It can access diverse data sources including HDFS, Cassandra, HBase, and S3</li>
</ul>
</li>
</ul>
<h3 id="why-fast"><strong>Why Fast?</strong></h3>
<p><strong>Advanced DAG (Directed Acyclic Graph) execution engine</strong></p>
<ul>
<li>It aims to rearrange and combine operators where possible to get the optimum performance</li>
<li>i.e., Map-then-Filter will be rearranged to Filter-then-Map</li>
</ul>
<p><strong>In-memory distributed computing</strong></p>
<ul>
<li><strong>It avoids disk writes and reads</strong></li>
<li><strong>It is achieved by the Resilient Distributed Datasets (RDDs)</strong></li>
</ul>
<h2 id="components"><strong>Components</strong></h2>
<figure><img src="/images/cloudInfraBasics/spark_components.png"
         alt="spark components" width="55%"/>
</figure>

<h2 id="resilient-distributed-datasets-rdds"><strong>Resilient Distributed Datasets</strong> (RDDs)</h2>
<h3 id="definition"><strong>Definition</strong></h3>
<ul>
<li><em><strong>A distributed collection of objects across a cluster with user- controlled partitioning &amp; storage</strong></em></li>
<li>The Spark’s <strong>core abstraction</strong> for working with data</li>
<li><em><strong>Resiliency</strong></em>: capable of automatically rebuilding on failure
<ul>
<li>Each RDD contains lineage information (how it is built)</li>
</ul>
</li>
</ul>
<h3 id="properties"><strong>Properties</strong></h3>
<ul>
<li>RDDs shard the data over a cluster, like a virtualized, distributed collection (analogous to HDFS)</li>
<li>RDDs support <em><strong>intelligent caching</strong></em>, which means no naive flushes of massive datasets to disk.
<ul>
<li>This feature alone allows Spark jobs to run 10-100x faster than comparable MapReduce jobs!</li>
</ul>
</li>
<li>The <strong>“resilient”</strong> part means they will reconstitute shards lost due to process/server crashes.</li>
<li>RDD is <strong>partitioned across multiple nodes</strong>. So, while the use of Spark will abstract away a lot of this partitioning from us, we need to know that RDDs will, in fact, <strong>be stored across the nodes</strong> in the Spark cluster.</li>
<li>Spark RDDs are <em><strong>immutable</strong></em>.</li>
<li>Spark RDDs are resilient, that is, even if one of the nodes on which the RDD resides crashes, then it can be reconstructed using its metadata.</li>
<li>Any operation which we specify on a Spark RDD will <strong>generate a new RDD</strong> with those modifications applied. So RDDs cannot be modified or updated without the operations resulting in the creation of new RDDs with updated data.</li>
</ul>
<h2 id="programming"><strong>Programming</strong></h2>
<p>Lambda function: anonymous + lambda x avoids null or illegal input</p>
<ul>
<li>Example 1: Spark WordCount:</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>    <span style="color:#f92672">import</span> sys
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">from</span> pyspark <span style="color:#f92672">import</span> SparkContext, SparkConf
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    conf <span style="color:#f92672">=</span> SparkConf()
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># create Spark context with necessary configuration</span>
</span></span><span style="display:flex;"><span>    sc <span style="color:#f92672">=</span> SparkContext<span style="color:#f92672">.</span>getOrCreate(conf<span style="color:#f92672">=</span>conf)
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># Conduct MapReduce and write the output to folder</span>
</span></span><span style="display:flex;"><span>    wordCounts <span style="color:#f92672">=</span> sc<span style="color:#f92672">.</span>textFile(<span style="color:#e6db74">&#34;/testData&#34;</span>)<span style="color:#f92672">.</span>flatMap(<span style="color:#66d9ef">lambda</span> line: line<span style="color:#f92672">.</span>split(<span style="color:#e6db74">&#34; &#34;</span>))\
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">.</span>map(<span style="color:#66d9ef">lambda</span> word: (word, <span style="color:#ae81ff">1</span>))<span style="color:#f92672">.</span>reduceByKey(<span style="color:#66d9ef">lambda</span> a,b: a <span style="color:#f92672">+</span> b)<span style="color:#f92672">.</span>saveAsTextFile(<span style="color:#e6db74">&#34;/output&#34;</span>)
</span></span></code></pre></div><ul>
<li>Example 2: count the most frequent words:
<ul>
<li>first turn the word list into key-value with each value assigned to 1</li>
<li>reduce the key-value pairs such that count the appearances: reduceByKey</li>
<li>flip the relationship to value-key pair → sortByKey</li>
<li>overall:
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>results_rdd <span style="color:#f92672">=</span> lines_rdd<span style="color:#f92672">.</span>flatMap(<span style="color:#66d9ef">lambda</span> x: x<span style="color:#f92672">.</span>split())<span style="color:#f92672">.</span>map(<span style="color:#66d9ef">lambda</span> x: (x,<span style="color:#ae81ff">1</span>))
</span></span><span style="display:flex;"><span>                        <span style="color:#f92672">.</span>reduceByKey(<span style="color:#66d9ef">lambda</span> x,y: x<span style="color:#f92672">+</span>y)
</span></span><span style="display:flex;"><span>                        <span style="color:#f92672">.</span>map(<span style="color:#66d9ef">lambda</span> x: (x[<span style="color:#ae81ff">1</span>],x[<span style="color:#ae81ff">0</span>]))<span style="color:#f92672">.</span>sortByKey(<span style="color:#66d9ef">False</span>)
</span></span></code></pre></div></li>
</ul>
</li>
</ul>
<h2 id="flexible-deployment"><strong>Flexible Deployment</strong></h2>
<figure class="img-center"><img src="/images/cloudInfraBasics/spark_deployment.png"
         alt="spark context" width="35%"/>
</figure>

<h2 id="spark-context"><strong>Spark Context</strong></h2>
<p><strong>SparkContext</strong> represents a Spark cluster’s connection that is useful in building <strong>RDDs</strong> and broadcast variables on the cluster.</p>
<ul>
<li>It enables your Spark Application to connect to the Spark Cluster using Resource Manager.</li>
<li>Before the creation of SparkContext, SparkConf must be created</li>
</ul>
<p>In earlier versions of Apache Spark 1.x, Spark RDDs were the major APIs. However, Spark RDDs require a lot of low-level coding and you need much manual coding.</p>
<ul>
<li>As a result, later versions were released to encapsulate Spark
RDDs into higher-level APIs, called <strong>Spark Dataframes</strong>.</li>
</ul>
<h2 id="spark-dataframes"><strong>Spark Dataframes</strong></h2>
<p>A history:
<figure class="img-center"><img src="/images/cloudInfraBasics/spark_history.png"
         alt="spark dataframe history" width="50%"/>
</figure>
</p>
<p>Advantages of Spark Dataframes over RDDs:</p>
<ul>
<li>At the minimum level, Spark still uses RDDs, but Dataframe API allows a <strong>much simpler interface</strong> to interact with the data, as well as providing a more natural look and feel, especially with people familiar with relational databases.</li>
<li>Spark Dataframes are like distributed in-memory tables with named columns and schemas, where each column has a specific data type: integer, string, array, map, real, date, timestamp, etc. To a human’s eye, a Spark DataFrame is <em><strong>like a table</strong></em></li>
<li>Dataframes can be <strong>constructed from a wide array of sources</strong>, such as structured data files, tables in Hive, external databases or existing RDDs.</li>
</ul>
<h3 id="spark-2x-entry-point">Spark 2.x Entry Point</h3>
<figure class="img-center"><img src="/images/cloudInfraBasics/spark_session.png"
         alt="spark session" width="40%"/>
</figure>

<h2 id="architecture"><strong>Architecture</strong></h2>
<p><figure class="img-center"><img src="/images/cloudInfraBasics/spark_architecture.png"
         alt="spark architecture" width="43%"/>
</figure>

The overall architecture for Spark is a typical <em><strong>master/worker</strong></em> configuration, where you have a master which coordinates the work across several workers.</p>
<ul>
<li>First, there is a <em><strong>driver</strong></em>, which is an application that uses the <em><strong>SparkContext</strong></em>.
<ul>
<li>In Spark 2.x, <em><strong>SparkSession</strong></em> was created to <strong>encapsulate</strong> SparkContext functionalities</li>
</ul>
</li>
<li>The <code>SparkContext</code> then refers to a <em><strong>Cluster Manager</strong></em> to interact with the various Workers.</li>
<li>Each Worker consists of <strong>one Executor and one or more Tasks</strong>.</li>
<li>It is the responsibility of the driver program to communicate</li>
</ul>
<h2 id="run-a-job"><strong>Run a Job</strong></h2>
<p><figure class="img-center"><img src="/images/cloudInfraBasics/spark_job.png"
         alt="spark run job" width="60%"/>
</figure>

Basic code:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> pyspark
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> pyspark <span style="color:#f92672">import</span> SparkContext, SparkConf, SQLContext
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> pyspark.sql <span style="color:#f92672">import</span> SparkSession
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>spark <span style="color:#f92672">=</span> SparkSession<span style="color:#f92672">.</span>builder \
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">.</span>appName(<span style="color:#e6db74">&#34;HW7_spark_session&#34;</span>) \
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">.</span>getOrCreate()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;Spark application name:&#34;</span>, spark<span style="color:#f92672">.</span>sparkContext<span style="color:#f92672">.</span>appName)
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;Master: &#34;</span>, spark<span style="color:#f92672">.</span>sparkContext<span style="color:#f92672">.</span>master)
</span></span></code></pre></div><h1 id="dataframe-operations"><strong>DataFrame Operations</strong></h1>
<h2 id="readwrite"><strong>Read/Write</strong></h2>
<p>The basic of reading data in Spark is through <code>DataFrameReader</code>. This can be accessed through SparkSession through the read attribute</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> pyspark <span style="color:#f92672">import</span> SparkFiles
</span></span><span style="display:flex;"><span>dataframe <span style="color:#f92672">=</span> spark<span style="color:#f92672">.</span>read<span style="color:#f92672">.</span>csv(SparkFiles<span style="color:#f92672">.</span>get(<span style="color:#e6db74">&#34;data.csv&#34;</span>), header<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>, inferSchema<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Or simply</span>
</span></span><span style="display:flex;"><span>dataframe <span style="color:#f92672">=</span> spark<span style="color:#f92672">.</span>read<span style="color:#f92672">.</span>csv(<span style="color:#e6db74">&#34;data.csv&#34;</span>, header<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>, inferSchema<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span></code></pre></div><h2 id="dataframe-schema"><strong>DataFrame Schema</strong></h2>
<p>Think about each dataframe as a table. The table <strong>MUST</strong> have a structure (e.g. column names and data types). In Spark, this structure is called <strong>Schema</strong>
<figure class="img-center"><img src="/images/cloudInfraBasics/spark_schema.png"
         alt="spark dataframe schema" width="45%"/>
</figure>
</p>
<h2 id="data-types"><strong>Data Types</strong></h2>
<table>
<thead>
<tr>
<th>Data type</th>
<th>Value assigned in Python</th>
<th>API to instantiate</th>
</tr>
</thead>
<tbody>
<tr>
<td>ByteType</td>
<td>int</td>
<td>DataTypes.ByteType</td>
</tr>
<tr>
<td>ShortType</td>
<td>int</td>
<td>DataTypes.ShortType</td>
</tr>
<tr>
<td>IntegerType</td>
<td>int</td>
<td>DataTypes.IntegerType</td>
</tr>
<tr>
<td>LongType</td>
<td>int</td>
<td>DataTypes.LongType</td>
</tr>
<tr>
<td>FloatType</td>
<td>float</td>
<td>DataTypes.FloatType</td>
</tr>
<tr>
<td>DoubleType</td>
<td>float</td>
<td>DataTypes.DoubleType</td>
</tr>
<tr>
<td>StringType</td>
<td>str</td>
<td>DataTypes.StringType</td>
</tr>
<tr>
<td>BooleanType</td>
<td>bool</td>
<td>DataTypes.BooleanType</td>
</tr>
<tr>
<td>DecimalType</td>
<td>decimal.Decimal</td>
<td>DecimalType</td>
</tr>
</tbody>
</table>
<h3 id="more-operations"><strong>More Operations</strong></h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>print (dataframe<span style="color:#f92672">.</span>columns)  <span style="color:#75715e"># get column names</span>
</span></span><span style="display:flex;"><span>print(dataframe<span style="color:#f92672">.</span>count())  <span style="color:#75715e"># get number of rows</span>
</span></span><span style="display:flex;"><span>dataframe<span style="color:#f92672">.</span>show(<span style="color:#ae81ff">5</span>, vertical<span style="color:#f92672">=</span>true)  <span style="color:#75715e"># show first 5 rows</span>
</span></span><span style="display:flex;"><span>dataframe<span style="color:#f92672">.</span>describe()<span style="color:#f92672">.</span>show()  <span style="color:#75715e"># get summary statistics, will print count, mean, stddev, min, max for numeric columns</span>
</span></span></code></pre></div><h1 id="spark-sql"><strong>Spark SQL</strong></h1>
<p><code>Spark SQL</code> in Spark Ecosystem:
<figure class="img-center"><img src="/images/cloudInfraBasics/spark_sql.png"
         alt="spark sql" width="40%"/>
</figure>

Once you have read-in your dataframe, you may want to conduct some operations on it. Most of these operations belong to the <strong>Spark SQL</strong> library.</p>
<ul>
<li>Spark SQL is part of the core distribution since Spark 1.0 (April 2014)</li>
<li>Spark SQL runs SQL and HiveQL queries together.</li>
</ul>
<h2 id="sql-dataframe-operations"><strong>SQL DataFrame Operations</strong></h2>
<ul>
<li>Relational operations (e.g., select, where, join, groupBy) via a Domain
Specific Language</li>
<li>Operators take <em><strong>expression</strong></em> objects</li>
<li>Operators build up an Abstract Syntax Tree (AST), which is then
optimized by <em><strong>Catalyst</strong></em>.</li>
<li>e.g.
<ul>
<li>display number of players with first name as &ldquo;John&rdquo;
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> pyspark.sql.functions <span style="color:#f92672">import</span> col
</span></span><span style="display:flex;"><span>dataframe<span style="color:#f92672">.</span>where(col(<span style="color:#e6db74">&#34;first_name&#34;</span>) <span style="color:#f92672">==</span> <span style="color:#e6db74">&#34;John&#34;</span>)<span style="color:#f92672">.</span>count()
</span></span></code></pre></div></li>
<li>Create a Subset Dataframe from your Dataframe
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>subset_df <span style="color:#f92672">=</span> dataframe<span style="color:#f92672">.</span>select(<span style="color:#e6db74">&#34;first_name&#34;</span>, <span style="color:#e6db74">&#34;last_name&#34;</span>, <span style="color:#e6db74">&#34;age&#34;</span>)
</span></span><span style="display:flex;"><span>subset_df<span style="color:#f92672">.</span>show(<span style="color:#ae81ff">5</span>)
</span></span></code></pre></div></li>
<li>Display unique values from a column in your dataframe
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>dataframe<span style="color:#f92672">.</span>select(<span style="color:#e6db74">&#34;LastName&#34;</span>)<span style="color:#f92672">.</span>distinct()<span style="color:#f92672">.</span>show(<span style="color:#ae81ff">10</span>)
</span></span></code></pre></div></li>
<li>Filter records in your dataframe
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> pyspark.sql.functions <span style="color:#f92672">import</span> col
</span></span><span style="display:flex;"><span>dataframe<span style="color:#f92672">.</span>select(<span style="color:#e6db74">&#34;nflId&#34;</span>, <span style="color:#e6db74">&#34;FirstName&#34;</span>, <span style="color:#e6db74">&#34;LastName&#34;</span>) \
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">.</span>where(col(<span style="color:#e6db74">&#34;FirstName&#34;</span> <span style="color:#f92672">==</span> <span style="color:#e6db74">&#34;John&#34;</span>))<span style="color:#f92672">.</span>show()
</span></span></code></pre></div></li>
<li>Convert SparkDataFrame into RDD and Vice Versa:
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>rdd <span style="color:#f92672">=</span> dataframe<span style="color:#f92672">.</span>rdd
</span></span><span style="display:flex;"><span>updated_df <span style="color:#f92672">=</span> rdd<span style="color:#f92672">.</span>toDF()
</span></span></code></pre></div></li>
</ul>
</li>
<li>How does <em>Catalyst</em> work?
<figure><img src="/images/cloudInfraBasics/spark_catalyst.png"
           alt="spark catalyst optimizer" width="50%"/>
  </figure>
</li>
</ul>
<h2 id="advantages-over-relational-query-languages"><strong>Advantages over Relational Query Languages</strong></h2>
<ul>
<li>Holistic optimization across functions composed in different languages.</li>
<li>Control structures (e.g., if, for)</li>
<li>Logical plan analyzed eagerly → identify code errors associated with data <em><strong>schema</strong></em> issues on the fly.</li>
</ul>
<h1 id="rdd-operations"><strong>RDD Operations</strong></h1>
<h2 id="transformations-vs-actions"><strong>Transformations vs Actions</strong></h2>
<h3 id="transformations"><strong>Transformations</strong></h3>
<p><strong>Transformations</strong> are where the Spark machinery can do its magic with lazy evaluation and clever algorithms to minimize communication and parallelize the processing.</p>
<ul>
<li>Generate a new RDD from existing one</li>
<li>Lazy/delay evaluation (not until an action performs): e.g. several transformations will be sent to catalyst optimizer, and it will not execute until an <strong>action</strong>. <strong>Actions</strong> are eagerly evaluated</li>
<li>If a job is to create another RDD from the input data, it is a transformation</li>
</ul>
<h3 id="actions"><strong>Actions</strong></h3>
<p>Actions are mostly used either <em><strong>at the end of the analysis</strong></em> when the data have been distilled down (collect), or <em><strong>along the way to &ldquo;peek&rdquo; at the process</strong></em> (count, take).</p>
<ul>
<li>Trigger a computation on RDD and do something with the results either
returning them to the user (driver) or saving them to external storage</li>
<li>Have immediate effect</li>
</ul>
<h2 id="programming-1"><strong>Programming</strong></h2>
<h3 id="single-rdd"><strong>Single RDD</strong></h3>
<p><strong>Transformations</strong>:</p>
<table>
<thead>
<tr>
<th>Transformation</th>
<th>Result</th>
</tr>
</thead>
<tbody>
<tr>
<td><em><strong>map</strong></em>(func)</td>
<td>Return a new RDD by passing each element through <em>func</em>. (Same Size)</td>
</tr>
<tr>
<td><em><strong>filter</strong></em>(func)</td>
<td>Return a new RDD by selecting the elements for which <em>func</em> returns true. (Fewer Elements)</td>
</tr>
<tr>
<td><em><strong>flatMap</strong></em>(func)</td>
<td><em>func</em> can return multiple items and generate a sequence, allowing flattening nested entries into a list. (More Elements)</td>
</tr>
<tr>
<td><em><strong>distinct</strong></em>()</td>
<td>Return an RDD with only distinct entries.</td>
</tr>
<tr>
<td><em><strong>sample</strong></em>(&hellip;)</td>
<td>Various options to create a subset of the RDD.</td>
</tr>
<tr>
<td><em><strong>union</strong></em>(RDD)</td>
<td>Return a union of the RDDs.</td>
</tr>
<tr>
<td><em><strong>intersection</strong></em>(RDD)</td>
<td>Return an intersection of the RDDs.</td>
</tr>
<tr>
<td><em><strong>subtract</strong></em>(RDD)</td>
<td>Remove argument RDD from other.</td>
</tr>
<tr>
<td><em><strong>cartesian</strong></em>(RDD)</td>
<td>Cartesian product of the RDDs.</td>
</tr>
<tr>
<td><em><strong>parallelize</strong></em>(list)</td>
<td>Create an RDD from this (Python) list (using a spark context).</td>
</tr>
</tbody>
</table>
<p><strong>Actions</strong>:</p>
<table>
<thead>
<tr>
<th>Action</th>
<th>Result</th>
</tr>
</thead>
<tbody>
<tr>
<td><em><strong>collect</strong></em>()</td>
<td>Return all the elements from the RDD.</td>
</tr>
<tr>
<td><em><strong>count</strong></em>()</td>
<td>Number of elements in RDD.</td>
</tr>
<tr>
<td><em><strong>countByValue</strong></em>()</td>
<td>List of times each value occurs in the RDD.</td>
</tr>
<tr>
<td><em><strong>reduce</strong></em>(func)</td>
<td>Aggregate the elements of the RDD by providing a function which combines any two into one (sum, min, max, …).</td>
</tr>
<tr>
<td><em><strong>first</strong></em>(), <em><strong>take</strong></em>(n)</td>
<td>Return the first, or first n elements.</td>
</tr>
<tr>
<td><em><strong>top</strong></em>(n)</td>
<td>Return the n highest valued elements of the RDDs.</td>
</tr>
<tr>
<td><em><strong>takeSample</strong></em>(&hellip;)</td>
<td>Various options to return a subset of the RDD.</td>
</tr>
<tr>
<td><em><strong>saveAsTextFile</strong></em>(path)</td>
<td>Write the elements as a text file.</td>
</tr>
<tr>
<td><em><strong>foreach</strong></em>(func)</td>
<td>Run the <em>func</em> on each element. Used for side-effects (updating accumulator variables) or interacting with external systems.</td>
</tr>
</tbody>
</table>
<h3 id="pair-rdd"><strong>Pair RDD</strong></h3>
<p>Key/Value organization is a simple, but often requires very efficient schema.</p>
<p>Spark provides special operations on RDDs that contain key/value pairs.</p>
<p>On the language (Python, Scala, Java) side, key/values are simply tuples. If you have an RDD all of whose elements happen to be tuples of two items, it is a Pair RDD and you can use the key/value operations that follow.</p>
<p><strong>Transformation</strong>:</p>
<table>
<thead>
<tr>
<th>Transformation</th>
<th>Result</th>
</tr>
</thead>
<tbody>
<tr>
<td><em><strong>reduceByKey</strong></em>(func)</td>
<td>Reduce values using <em>func</em>, but on a key-by-key basis. That is, combine values with the same key.</td>
</tr>
<tr>
<td><em><strong>groupByKey</strong></em>()</td>
<td>Combine values with same key. Each key ends up with a list.</td>
</tr>
<tr>
<td><em><strong>sortByKey</strong></em>()</td>
<td>Return an RDD sorted by key.</td>
</tr>
<tr>
<td><em><strong>mapValues</strong></em>(func)</td>
<td>Use <em>func</em> to change values, but not key.</td>
</tr>
<tr>
<td><em><strong>keys</strong></em>()</td>
<td>Return an RDD of only keys.</td>
</tr>
<tr>
<td><em><strong>values</strong></em>()</td>
<td>Return an RDD of only values.</td>
</tr>
</tbody>
</table>
<p><strong>Action</strong>:</p>
<table>
<thead>
<tr>
<th>Action</th>
<th>Result</th>
</tr>
</thead>
<tbody>
<tr>
<td><em><strong>countByKey</strong></em>()</td>
<td>Count the number of elements for each key.</td>
</tr>
<tr>
<td><em><strong>lookup</strong></em>(key)</td>
<td>Return all the values for this key.</td>
</tr>
</tbody>
</table>
<h3 id="two-pair"><strong>Two Pair</strong></h3>
<table>
<thead>
<tr>
<th>Transformation</th>
<th>Result</th>
</tr>
</thead>
<tbody>
<tr>
<td><em><strong>subtractByKey</strong></em>(otherRDD)</td>
<td>Remove elements with a key present in other RDD.</td>
</tr>
<tr>
<td><em><strong>join</strong></em>(otherRDD)</td>
<td>Inner join: Return an RDD containing all pairs of elements with matching keys in self and other. Each pair of elements will be returned as a <code>(k, (v1, v2))</code> tuple, where <code>(k, v1)</code> is in self and <code>(k, v2)</code> is in other.</td>
</tr>
<tr>
<td><em><strong>leftOuterJoin</strong></em>(otherRDD)</td>
<td>For each element <code>(k, v)</code> in self, the resulting RDD will either contain all pairs <code>(k, (v, w))</code> for w in other, or the pair <code>(k, (v, None))</code> if no elements in other have key k.</td>
</tr>
<tr>
<td><em><strong>rightOuterJoin</strong></em>(otherRDD)</td>
<td>For each element (k, w) in other, the resulting RDD will either contain all pairs <code>(k, (v, w))</code> for v in this, or the pair (k, (None, w)) if no elements in self have key k.</td>
</tr>
<tr>
<td><em><strong>cogroup</strong></em>(otherRDD)</td>
<td>Group data from both RDDs by key.</td>
</tr>
</tbody>
</table>
<h1 id="top-n-example"><strong>Top-N Example</strong></h1>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>lines_rdd <span style="color:#f92672">=</span> scl<span style="color:#f92672">.</span>textFile(<span style="color:#e6db74">&#34;inputData.txt&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Count the number of lines</span>
</span></span><span style="display:flex;"><span>lines_rdd<span style="color:#f92672">.</span>count()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Number of words</span>
</span></span><span style="display:flex;"><span>words_rdd <span style="color:#f92672">=</span> lines_rdd<span style="color:#f92672">.</span>flatMap(<span style="color:#66d9ef">lambda</span> x: x<span style="color:#f92672">.</span>split())
</span></span><span style="display:flex;"><span>words_rdd<span style="color:#f92672">.</span>count()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Number of distinct words</span>
</span></span><span style="display:flex;"><span>words_rdd<span style="color:#f92672">.</span>distinct()<span style="color:#f92672">.</span>count()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Count the occurrences of each word </span>
</span></span><span style="display:flex;"><span>key_value_rdd <span style="color:#f92672">=</span> words_rdd<span style="color:#f92672">.</span>map(<span style="color:#66d9ef">lambda</span> x: (x, <span style="color:#ae81ff">1</span>))
</span></span><span style="display:flex;"><span>word_count_rdd <span style="color:#f92672">=</span> key_value_rdd<span style="color:#f92672">.</span>reduceByKey(<span style="color:#66d9ef">lambda</span> x, y: x <span style="color:#f92672">+</span> y)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># find top-n frequent words</span>
</span></span><span style="display:flex;"><span>flipped_rdd <span style="color:#f92672">=</span> word_count_rdd<span style="color:#f92672">.</span>map(<span style="color:#66d9ef">lambda</span> x: (x[<span style="color:#ae81ff">1</span>], x[<span style="color:#ae81ff">0</span>]))
</span></span><span style="display:flex;"><span>sorted_rdd <span style="color:#f92672">=</span> flipped_rdd<span style="color:#f92672">.</span>sortByKey(<span style="color:#66d9ef">False</span>)
</span></span></code></pre></div><p><strong>Combine all in one</strong>:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>results_rdd <span style="color:#f92672">=</span> lines_rdd<span style="color:#f92672">.</span>flatMap(<span style="color:#66d9ef">lambda</span> x: x<span style="color:#f92672">.</span>split())<span style="color:#f92672">.</span>map(<span style="color:#66d9ef">lambda</span> x: (x,<span style="color:#ae81ff">1</span>))
</span></span><span style="display:flex;"><span>                        <span style="color:#f92672">.</span>reduceByKey(<span style="color:#66d9ef">lambda</span> x,y: x<span style="color:#f92672">+</span>y)
</span></span><span style="display:flex;"><span>                        <span style="color:#f92672">.</span>map(<span style="color:#66d9ef">lambda</span> x: (x[<span style="color:#ae81ff">1</span>],x[<span style="color:#ae81ff">0</span>]))<span style="color:#f92672">.</span>sortByKey(<span style="color:#66d9ef">False</span>)
</span></span></code></pre></div><h1 id="extra-reading"><strong>Extra Reading</strong></h1>
<p><a href="https://spark.apache.org/docs/2.3.0/sql-programming-guide.html">Spark SQL, Dataframe and Dataset Guide</a></p>
<p><a href="https://spark.apache.org/docs/latest/sql-performance-tuning.html">Spark Optimizations</a></p>

                    
                    <HR width="100%" id="EOF">
		    <p style="color:#777;">Last modified on 2025-12-01</p>
                    
                </div>
            </div>
            
            
            <nav class="post-pagination">

                
                <a class="newer-posts">
			Next<br>No newer posts.
                </a>
                
                
                
                <a class="older-posts" href="/tech/cloud_infra_basics/hadoop_yarn/">
			Previous<br>Hadoop - YARN
                </a>
                
            </nav>
            <div class="post-comment-wrapper">
                












<script src="https://giscus.app/client.js"
        data-repo=""
        data-repo-id=""
        data-category=""
        data-category-id=""
        data-mapping=""
        data-strict=""
        data-reactions-enabled=""
        data-emit-metadata=""
        data-input-position=""
        data-theme=""
        data-lang=""
        crossorigin="anonymous"
        async>
</script>

            </div>
        </div>
    </div>


                    </div>
            </div><div id="sideContainer" class="side-container">
    
    <a class="a-block nav-head false" href="http://allenhsm.github.io/">
    
        <div class="nav-title">
            Allen&#39;s Blog
        </div>
        
    </a>

    <div class="nav-link-list">
        
        
            
            
            
            
            
            <a class="a-block nav-link-item false" href="/posts">
                Archive
            </a>
            
        
            
            
            
            
            
            <a class="a-block nav-link-item false" href="/tags/reading">
                Reading
            </a>
            
        
            
            
            
            
            
            <a class="a-block nav-link-item false" href="/tags/travelogue">
                Travelogue
            </a>
            
        
            
            
            
            
            
            <a class="a-block nav-link-item false" href="/categories">
                Categories
            </a>
            
        
            
            
            
            
            
            <a class="a-block nav-link-item false" href="/about/about_me">
                About Me
            </a>
            
        
            
            
            
            
            
            <a class="a-block nav-link-item false" href="/tags">
                Tags
            </a>
            
        
    </div>

    

    <div class="nav-footer">
        
Hugo Theme <a href="https://github.com/amazingrise/hugo-theme-diary">Diary</a> by <a href="https://risehere.net/">Rise</a>
<br>
Ported from <a href="https://mak1t0.cc/" target="_blank" rel="noreferrer noopener">Makito</a>'s <a href="https://github.com/SumiMakito/hexo-theme-journal/" target="_blank" rel="noreferrer noopener">Journal.</a> <br>
<br>

&copy;
	
	This is a customized copyright.
	

    </div>
    
</div><div id="extraContainer" class="extra-container">
    <div class="toc-wrapper">
        

        
        <div class="toc">


	<div class="toc-content">
	
		
		
		
		<center>- CATALOG -</center>
		
		
		<ul>
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#why-spark" class="nav-why-spark">
									Why Spark
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#spark" class="nav-spark">
									Spark
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
							
								
									<ul>
								
							
						
						
							<li>
								<a href="#basics" class="nav-basics">
									Basics
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#ecosystem" class="nav-ecosystem">
									Ecosystem
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#engine" class="nav-engine">
									Engine
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
							
								
									<ul>
								
							
						
						
							<li>
								<a href="#why-fast" class="nav-why-fast">
									Why Fast?
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
							
								</ul>
							
						
						
						
							<li>
								<a href="#components" class="nav-components">
									Components
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#resilient-distributed-datasets-rdds" class="nav-resilient-distributed-datasets-rdds">
									Resilient Distributed Datasets (RDDs)
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
							
								
									<ul>
								
							
						
						
							<li>
								<a href="#definition" class="nav-definition">
									Definition
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#properties" class="nav-properties">
									Properties
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
							
								</ul>
							
						
						
						
							<li>
								<a href="#programming" class="nav-programming">
									Programming
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#flexible-deployment" class="nav-flexible-deployment">
									Flexible Deployment
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#spark-context" class="nav-spark-context">
									Spark Context
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#spark-dataframes" class="nav-spark-dataframes">
									Spark Dataframes
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
							
								
									<ul>
								
							
						
						
							<li>
								<a href="#spark-2x-entry-point" class="nav-spark-2x-entry-point">
									Spark 2.x Entry Point
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
							
								</ul>
							
						
						
						
							<li>
								<a href="#architecture" class="nav-architecture">
									Architecture
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#run-a-job" class="nav-run-a-job">
									Run a Job
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
							
								</ul>
							
						
						
						
							<li>
								<a href="#dataframe-operations" class="nav-dataframe-operations">
									DataFrame Operations
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
							
								
									<ul>
								
							
						
						
							<li>
								<a href="#readwrite" class="nav-readwrite">
									Read/Write
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#dataframe-schema" class="nav-dataframe-schema">
									DataFrame Schema
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#data-types" class="nav-data-types">
									Data Types
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
							
								
									<ul>
								
							
						
						
							<li>
								<a href="#more-operations" class="nav-more-operations">
									More Operations
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
							
								</ul>
							
								</ul>
							
						
						
						
							<li>
								<a href="#spark-sql" class="nav-spark-sql">
									Spark SQL
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
							
								
									<ul>
								
							
						
						
							<li>
								<a href="#sql-dataframe-operations" class="nav-sql-dataframe-operations">
									SQL DataFrame Operations
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#advantages-over-relational-query-languages" class="nav-advantages-over-relational-query-languages">
									Advantages over Relational Query Languages
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
							
								</ul>
							
						
						
						
							<li>
								<a href="#rdd-operations" class="nav-rdd-operations">
									RDD Operations
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
							
								
									<ul>
								
							
						
						
							<li>
								<a href="#transformations-vs-actions" class="nav-transformations-vs-actions">
									Transformations vs Actions
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
							
								
									<ul>
								
							
						
						
							<li>
								<a href="#transformations" class="nav-transformations">
									Transformations
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#actions" class="nav-actions">
									Actions
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
							
								</ul>
							
						
						
						
							<li>
								<a href="#programming-1" class="nav-programming-1">
									Programming
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
							
								
									<ul>
								
							
						
						
							<li>
								<a href="#single-rdd" class="nav-single-rdd">
									Single RDD
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#pair-rdd" class="nav-pair-rdd">
									Pair RDD
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#two-pair" class="nav-two-pair">
									Two Pair
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
							
								</ul>
							
								</ul>
							
						
						
						
							<li>
								<a href="#top-n-example" class="nav-top-n-example">
									Top-N Example
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#extra-reading" class="nav-extra-reading">
									Extra Reading
								</a>
							</li>
						
						
					
				
			
		</ul>
	</div>

</div>
        
    </div>
    <div class="pagination">
        <a id="globalBackToTop" class="pagination-action animated-visibility" href="#top"
            :class="{ invisible: scrollY == 0 }">
            <i class="material-icons pagination-action-icon">
                keyboard_arrow_up
            </i>
        </a>
        
        <a type="button" class="pagination-action" id="darkModeToggleButton">
            <span class="material-icons pagination-action-icon" id="darkModeToggleIcon">
                dark_mode
            </span>
        </a>
        
        
    </div>
</div><div id="single-column-footer">
Hugo Theme <a href="https://github.com/amazingrise/hugo-theme-diary">Diary</a> by <a href="https://risehere.net/">Rise</a>
<br>
Ported from <a href="https://mak1t0.cc/" target="_blank" rel="noreferrer noopener">Makito</a>'s <a href="https://github.com/SumiMakito/hexo-theme-journal/" target="_blank" rel="noreferrer noopener">Journal.</a> <br>
<br>

&copy;
	
	This is a customized copyright.
	
</div>
            </div>
    
    <script src="/js/journal.js"></script></body>
</html>
