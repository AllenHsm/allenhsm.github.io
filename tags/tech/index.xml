<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>tech on Allen&#39;s Blog</title>
    <link>http://allenhsm.github.io/tags/tech/</link>
    <description>Recent content in tech on Allen&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>This is a customized copyright.</copyright>
    <lastBuildDate>Sat, 29 Nov 2025 04:56:00 -0500</lastBuildDate><atom:link href="http://allenhsm.github.io/tags/tech/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Hadoop - YARN</title>
      <link>http://allenhsm.github.io/tech/cloud_infra_basics/hadoop_yarn/</link>
      <pubDate>Sat, 29 Nov 2025 04:56:00 -0500</pubDate>
      
      <guid>http://allenhsm.github.io/tech/cloud_infra_basics/hadoop_yarn/</guid>
      <description>Yarn Brief History Hadoop 1.x Core components: MapReduce and HDFS Structure: HDFS: NameNode + DataNodes MapReduce (MRv1): JobTracker + TaskTrackers JobTracker did everything: resource management, job scheduling, tracking tasks, failure handling Also a single point of failure and a scaling bottleneck MapReduce = computation engine + resource manager in one Only MapReduce jobs were supported Hadoop 2.x Now Hadoop has three logical layers: HDFS: storage layer NameNode + DataNodes YARN: resource management layer ResourceManager + NodeManagers + ApplicationMasters MapReduce (MRv2): computation layer Runs on top of YARN as one of many application frameworks Key improvements Separated resource management from computation MapReduce no longer monopolizes the cluster Allowed more engines: Spark, Tez, Flink, Storm, etc.</description>
    </item>
    
    <item>
      <title>Hadoop - MapReduce</title>
      <link>http://allenhsm.github.io/tech/cloud_infra_basics/hadoop_mapreduce/</link>
      <pubDate>Sat, 29 Nov 2025 04:55:54 -0500</pubDate>
      
      <guid>http://allenhsm.github.io/tech/cloud_infra_basics/hadoop_mapreduce/</guid>
      <description>Intro How traditional distributed system dealing with data: It is too complicated to build a distributed system from scratch Now MapReduce comes in and abbreviates this process by taking care of most parts, except for collecting results, and processing the data before handling failures. MapReduce Definition A programming model and an associated implementation for processing and generating large data sets with a parallel, distributed algorithm on a Hadoop cluster. It abstracts the problem from disk reads and writes, transforming it into a computation over sets for keys and values It works as a batch query processor that can run an ad hoc query against your whole data set and get result in a reasonable time.</description>
    </item>
    
    <item>
      <title>Hadoop - HDFS</title>
      <link>http://allenhsm.github.io/tech/cloud_infra_basics/hadoop_hdfs/</link>
      <pubDate>Sat, 29 Nov 2025 01:27:18 -0500</pubDate>
      
      <guid>http://allenhsm.github.io/tech/cloud_infra_basics/hadoop_hdfs/</guid>
      <description>Intro Motivation for Hadoop Handle big data! that exceeds single machine&amp;rsquo;s storage and computing capacity Storage and Analysis Storage capacity increases faster than then access speeds. Need parallel data access to get things done quickly 1 machine accessing 1000 GB is much slower than 100 machines, each is accessing 10 GB. Shared access for efficiency and scalability Challenges Analysis tasks need to combine data from multiple sources Need a paradigm that transparently splits and merges data Challenge of parallel data access to and from multiple disks Hardware failure Why Hadoop We need Open-source software framework for storing data and running applications on clusters of commodity hardware -&amp;gt; Hadoop is cheap to implement and expand Provides massive storage for any kind of data, enormous processing power and the ability to handle virtually limitless concurrent tasks or jobs -&amp;gt; Hadoop is scalable Hadoop Basics Component Architecture HDFS: Hadoop Distributed File System Designed to provide highly fault-tolerant and to be deployed on low-cost hardware MapReduce: A framework for processing data in batch - BSP (Bulk Synchronous Parallel) Enables distributed processing of large data sets across clusters of computers using simple programming models History HDFS Distributed File System A client/server-based application that allows clients to access and process data stored on the server as if they were on their own computer Client/Server arch: Clients request services and resources from a centralized server.</description>
    </item>
    
    <item>
      <title>Concepts in Cloud Infra</title>
      <link>http://allenhsm.github.io/tech/cloud_infra_basics/concepts_in_cloud_infra/</link>
      <pubDate>Fri, 28 Nov 2025 19:28:43 -0500</pubDate>
      
      <guid>http://allenhsm.github.io/tech/cloud_infra_basics/concepts_in_cloud_infra/</guid>
      <description>Cloud Types Public Cloud Services offered over the public internet and available to anyone who wants to purchase them. Typically owned and operated by third-party cloud service providers (e.g., AWS, Azure, Google Cloud). It exists on the premise of the cloud service provider Advantage: cost. Concern: Security. However there are some public cloud providers that have demonstrated strong security measures. Private Cloud Implemented within the internal IT environment of the company, typically managed by the company or a third party vendor In private clouds, the servers and storage devices may exist on premist or off-premise Private clouds can deliver IaaS internally to employees or business units through an intranet or the Internet via a virtual private network (VPN), as well as software (applications) or storage as services to its branch offices Examples of services delivered through the private cloud include database on demand, email on demand, and storage on demand.</description>
    </item>
    
    <item>
      <title>IaC &amp; Terraform</title>
      <link>http://allenhsm.github.io/tech/cloud_infra_basics/terraform/</link>
      <pubDate>Fri, 28 Nov 2025 00:04:22 -0500</pubDate>
      
      <guid>http://allenhsm.github.io/tech/cloud_infra_basics/terraform/</guid>
      <description>Infrastructure as Code Definition: Write and execute code to define, deploy update, and destroy our infra. Why we automate deployment? reliable, efficient, repeatable, safe releases, multiple environment, maximum scalability Types of IaC tools Ad-hoc Scripts The easiest and most straightforward approach of automating anything ad-hoc tools run on single core tool, like cloud shell, which connects to a VM with only 5GB storage space, if you need more, you have to upload the file to cloud bucket or sth, and use the shell to read from it.</description>
    </item>
    
    <item>
      <title>Apache Kafka</title>
      <link>http://allenhsm.github.io/tech/cloud_infra_basics/apache_kafka/</link>
      <pubDate>Tue, 25 Nov 2025 22:10:31 -0500</pubDate>
      
      <guid>http://allenhsm.github.io/tech/cloud_infra_basics/apache_kafka/</guid>
      <description>Why Kafka? Problem of Request-Response Architecture: Kubernetes offers the ability to (de)scale your applications to respond to user requests in a meaningful amount of time. Process of request-response architecture: user sends a request to your application k8s master reroutes the request to an available pod, not enough pods HPA Still not enough VPA more requests Connection timeout Interruption If the number of user requests continue to increase beyond your K8s cluster resources, 1) your k8s master won&amp;rsquo;t have enough memory or processing power to reroute the incoming traffic, or 2) there are no available pods to process requests, and no more pods can be created.</description>
    </item>
    
    <item>
      <title>Deployment Orchestration</title>
      <link>http://allenhsm.github.io/tech/cloud_infra_basics/deployment_orchestration/</link>
      <pubDate>Sun, 23 Nov 2025 21:01:28 -0500</pubDate>
      
      <guid>http://allenhsm.github.io/tech/cloud_infra_basics/deployment_orchestration/</guid>
      <description>Container Orchestration The automatic process of managing or scheduling the work of individual containers for applications based on microservices within multiple clusters. Orchestration tools: Kubernetes, Docker Swarm, Apache Mesos, CoreOS rkt
Kubernetes An open-source container management tool which automates container deployment, container (de)scaling, container load balancing Can group &amp;ldquo;n&amp;rdquo; number of containers into one logical unit called &amp;ldquo;POD&amp;rdquo;, easy to manage and deploy Features Automated bin packing: via packaging software and automatically placing it/containers based on their resource requirements and other constraints, while not sacrificing availability.</description>
    </item>
    
    <item>
      <title>Containerization</title>
      <link>http://allenhsm.github.io/tech/cloud_infra_basics/containerization/</link>
      <pubDate>Sat, 22 Nov 2025 22:25:09 -0500</pubDate>
      
      <guid>http://allenhsm.github.io/tech/cloud_infra_basics/containerization/</guid>
      <description>Virtual Machines to Containers VM is too heavy for a simple process as it boots a whole OS every time. Containers are isolated, but share OS, and where appropriate, also bins/libs. So SDE focuses more on app. Comparison:
Lightweight: Containerization avoids duplication of app Bins/libs, and only save the modifications did by different containers, without changing the original binaries. Security: VM is more secure because of full isolation while Container has only process level isolation.</description>
    </item>
    
    <item>
      <title>Virtualization</title>
      <link>http://allenhsm.github.io/tech/cloud_infra_basics/virtualization/</link>
      <pubDate>Sat, 22 Nov 2025 21:01:07 -0500</pubDate>
      
      <guid>http://allenhsm.github.io/tech/cloud_infra_basics/virtualization/</guid>
      <description>Virtualization to create independent execution environment, leveraging the abstract form of the hardware capability.
More Defi of Virtualization abstracts the hardware of computing infrastructure into several different execution environments. Creates the illusion that each separate environment is running on its own private computing infrastructure. Makes servers, workstations, storage, network, and other systems independent of the physical hardware layer. It is the fundamental technology for cloud infrastructure. Virtual resources can be started and stooped easily and quickly on demand.</description>
    </item>
    
    <item>
      <title>Brief Intro to Cloud</title>
      <link>http://allenhsm.github.io/tech/cloud_infra_basics/intro_to_cloud/</link>
      <pubDate>Fri, 21 Nov 2025 03:10:21 -0500</pubDate>
      
      <guid>http://allenhsm.github.io/tech/cloud_infra_basics/intro_to_cloud/</guid>
      <description>What is Cloud In simple words, Cloud = SCN (Lots of Storage + Computer C(omputation)ycles nearby + Network bandwidth)
In the industry, “Cloud” refers to large Internet services running on 10,000s of machines (Amazon, Google, Microsoft, etc.)
To be specific, Cloud is a model that offers following characteristics:
On-demand self-service: no human intervention needed to get resources Broad network access: access from anywhere Resource pooling: provider shares resources to serve multiple consumers Rapid elasticity Measured service Multi-tenancy Why Cloud Three main reasons:</description>
    </item>
    
    <item>
      <title>Cloud Infra Basics - 14848</title>
      <link>http://allenhsm.github.io/tech/cloud_infra_basics/cloud_infra_basics/</link>
      <pubDate>Fri, 21 Nov 2025 02:03:20 -0500</pubDate>
      
      <guid>http://allenhsm.github.io/tech/cloud_infra_basics/cloud_infra_basics/</guid>
      <description>Credit: This is a review and summary of the concepts and techniques I have learned so far in CMU course 14848. This course is designed and delivered by Professor Mohamed Farag, a helpful and passionate lecturer, a knowledgeable and chill guy. So most of the materials in this series of posts are from his lectures and slides.
Intro This course consists of two parts:
cloud infrastructure components coding in these components This series of posts will follow the same structure and review each specific topics separately.</description>
    </item>
    
  </channel>
</rss>
